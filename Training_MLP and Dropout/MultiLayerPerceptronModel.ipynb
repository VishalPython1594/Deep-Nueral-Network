{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972695bf-f9af-41c5-9c1e-fbfa018b037b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KUMAR SUNDRAM\\\\Desktop\\\\Adv AI - 1st June 2024\\\\DNN'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd634a5d-eac8-4da6-8dab-db741bc5b529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender   Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male  19.0          19000.0          0\n",
       "1  15810944    Male  35.0          20000.0          0\n",
       "2  15668575  Female  26.0          43000.0          0\n",
       "3  15603246  Female  27.0          57000.0          0\n",
       "4  15804002    Male  19.0          76000.0          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7c295f-8186-4117-8811-401150cea242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  EstimatedSalary  Purchased\n",
       "0  19.0          19000.0          0\n",
       "1  35.0          20000.0          0\n",
       "2  26.0          43000.0          0\n",
       "3  27.0          57000.0          0\n",
       "4  19.0          76000.0          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.iloc[:,2:]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fabde6-c3fe-4b70-95bd-ac3e550f7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c99514-73c0-4e4e-b1fb-02efc51e54cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>57000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>76000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  EstimatedSalary\n",
       "0  19.0          19000.0\n",
       "1  35.0          20000.0\n",
       "2  26.0          43000.0\n",
       "3  27.0          57000.0\n",
       "4  19.0          76000.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7086f7-6310-46fa-ad6a-f057e9feac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7897958e-e7cd-4e89-b32a-eea18f0cc7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.781797</td>\n",
       "      <td>-1.490046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253587</td>\n",
       "      <td>-1.460681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.113206</td>\n",
       "      <td>-0.785290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.017692</td>\n",
       "      <td>-0.374182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.781797</td>\n",
       "      <td>0.183751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.797057</td>\n",
       "      <td>-0.844019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1.274623</td>\n",
       "      <td>-1.372587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.179110</td>\n",
       "      <td>-1.460681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-0.158074</td>\n",
       "      <td>-1.078938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.083596</td>\n",
       "      <td>-0.990844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -1.781797 -1.490046\n",
       "1   -0.253587 -1.460681\n",
       "2   -1.113206 -0.785290\n",
       "3   -1.017692 -0.374182\n",
       "4   -1.781797  0.183751\n",
       "..        ...       ...\n",
       "395  0.797057 -0.844019\n",
       "396  1.274623 -1.372587\n",
       "397  1.179110 -1.460681\n",
       "398 -0.158074 -1.078938\n",
       "399  1.083596 -0.990844\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaler = scaler.fit_transform(x)\n",
    "pd.DataFrame(x_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27309cf5-f23b-4330-98f8-a179e749a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaler, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81bf274-6f2e-4cee-871d-4078723aa9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1adfd3-6fff-4db8-bbad-8c326d80c92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUMAR SUNDRAM\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.5521 - loss: 0.6845 - val_accuracy: 0.6375 - val_loss: 0.6624\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6261 - loss: 0.6679 - val_accuracy: 0.6375 - val_loss: 0.6599\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6359 - loss: 0.6558 - val_accuracy: 0.6375 - val_loss: 0.6665\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6807 - loss: 0.6231 - val_accuracy: 0.6375 - val_loss: 0.6587\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6443 - loss: 0.6569 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6449 - loss: 0.6531 - val_accuracy: 0.6375 - val_loss: 0.6568\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6580 - loss: 0.6430 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6248 - loss: 0.6629 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6723 - loss: 0.6376 - val_accuracy: 0.6375 - val_loss: 0.6558\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6407 - loss: 0.6583 - val_accuracy: 0.6375 - val_loss: 0.6567\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6599 - loss: 0.6509 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6267 - loss: 0.6628 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6307 - loss: 0.6593 - val_accuracy: 0.6375 - val_loss: 0.6559\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6324 - loss: 0.6601 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6761 - loss: 0.6354 - val_accuracy: 0.6375 - val_loss: 0.6551\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6550 - loss: 0.6464 - val_accuracy: 0.6375 - val_loss: 0.6554\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6509 - loss: 0.6481 - val_accuracy: 0.6375 - val_loss: 0.6595\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6703 - loss: 0.6340 - val_accuracy: 0.6375 - val_loss: 0.6578\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6276 - loss: 0.6624 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6355 - loss: 0.6596 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6045 - loss: 0.6770 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6423 - loss: 0.6536 - val_accuracy: 0.6375 - val_loss: 0.6573\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6350 - loss: 0.6583 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6419 - loss: 0.6528 - val_accuracy: 0.6375 - val_loss: 0.6564\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6358 - loss: 0.6577 - val_accuracy: 0.6375 - val_loss: 0.6548\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6482 - loss: 0.6497 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6536 - loss: 0.6466 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6156 - loss: 0.6703 - val_accuracy: 0.6375 - val_loss: 0.6565\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6441 - loss: 0.6517 - val_accuracy: 0.6375 - val_loss: 0.6606\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6124 - loss: 0.6795 - val_accuracy: 0.6375 - val_loss: 0.6559\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6255 - loss: 0.6608 - val_accuracy: 0.6375 - val_loss: 0.6561\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6459 - loss: 0.6510 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6614 - loss: 0.6405 - val_accuracy: 0.6375 - val_loss: 0.6551\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6392 - loss: 0.6546 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5983 - loss: 0.6773 - val_accuracy: 0.6375 - val_loss: 0.6564\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6256 - loss: 0.6657 - val_accuracy: 0.6375 - val_loss: 0.6556\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6356 - loss: 0.6569 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6082 - loss: 0.6702 - val_accuracy: 0.6375 - val_loss: 0.6557\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6521 - loss: 0.6486 - val_accuracy: 0.6375 - val_loss: 0.6558\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5949 - loss: 0.6869 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6305 - loss: 0.6593 - val_accuracy: 0.6375 - val_loss: 0.6569\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6457 - loss: 0.6523 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6677 - loss: 0.6387 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6611 - loss: 0.6415 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6698 - loss: 0.6377 - val_accuracy: 0.6375 - val_loss: 0.6551\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6619 - loss: 0.6414 - val_accuracy: 0.6375 - val_loss: 0.6559\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7073 - loss: 0.6271 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6325 - loss: 0.6611 - val_accuracy: 0.6375 - val_loss: 0.6565\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6420 - loss: 0.6532 - val_accuracy: 0.6375 - val_loss: 0.6573\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6175 - loss: 0.6716 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6606 - loss: 0.6432 - val_accuracy: 0.6375 - val_loss: 0.6567\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6057 - loss: 0.6815 - val_accuracy: 0.6375 - val_loss: 0.6560\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6494 - loss: 0.6496 - val_accuracy: 0.6375 - val_loss: 0.6568\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6547 - loss: 0.6454 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6493 - loss: 0.6488 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6325 - loss: 0.6587 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6268 - loss: 0.6616 - val_accuracy: 0.6375 - val_loss: 0.6554\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6664 - loss: 0.6374 - val_accuracy: 0.6375 - val_loss: 0.6560\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6548 - loss: 0.6440 - val_accuracy: 0.6375 - val_loss: 0.6557\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6321 - loss: 0.6587 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6480 - loss: 0.6508 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6251 - loss: 0.6636 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6290 - loss: 0.6607 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6645 - loss: 0.6404 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6515 - loss: 0.6470 - val_accuracy: 0.6375 - val_loss: 0.6548\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6506 - loss: 0.6488 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6241 - loss: 0.6628 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6393 - loss: 0.6546 - val_accuracy: 0.6375 - val_loss: 0.6563\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6245 - loss: 0.6651 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6546 - loss: 0.6465 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6747 - loss: 0.6326 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6436 - loss: 0.6517 - val_accuracy: 0.6375 - val_loss: 0.6554\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6540 - loss: 0.6476 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6686 - loss: 0.6369 - val_accuracy: 0.6375 - val_loss: 0.6578\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6422 - loss: 0.6531 - val_accuracy: 0.6375 - val_loss: 0.6563\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6339 - loss: 0.6575 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6353 - loss: 0.6571 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6682 - loss: 0.6378 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6719 - loss: 0.6346 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6454 - loss: 0.6517 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6295 - loss: 0.6607 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6575 - loss: 0.6442 - val_accuracy: 0.6375 - val_loss: 0.6553\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6387 - loss: 0.6549 - val_accuracy: 0.6375 - val_loss: 0.6548\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 0.6599 - val_accuracy: 0.6375 - val_loss: 0.6554\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 0.6613 - val_accuracy: 0.6375 - val_loss: 0.6563\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6630 - loss: 0.6409 - val_accuracy: 0.6375 - val_loss: 0.6555\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6159 - loss: 0.6701 - val_accuracy: 0.6375 - val_loss: 0.6562\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6165 - loss: 0.6652 - val_accuracy: 0.6375 - val_loss: 0.6579\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6207 - loss: 0.6700 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6579 - loss: 0.6428 - val_accuracy: 0.6375 - val_loss: 0.6550\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6470 - loss: 0.6499 - val_accuracy: 0.6375 - val_loss: 0.6548\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6619 - loss: 0.6413 - val_accuracy: 0.6375 - val_loss: 0.6556\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6627 - loss: 0.6393 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6536 - loss: 0.6459 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6223 - loss: 0.6637 - val_accuracy: 0.6375 - val_loss: 0.6548\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6422 - loss: 0.6523 - val_accuracy: 0.6375 - val_loss: 0.6569\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6499 - loss: 0.6488 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6733 - loss: 0.6339 - val_accuracy: 0.6375 - val_loss: 0.6549\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6524 - loss: 0.6472 - val_accuracy: 0.6375 - val_loss: 0.6552\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6374 - loss: 0.6551 - val_accuracy: 0.6375 - val_loss: 0.6555\n"
     ]
    }
   ],
   "source": [
    "# Vanishing Gradient problem occurs\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='sigmoid', input_dim=2))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec95670b-7063-4cf6-961e-9836bb47ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7316 - loss: 0.6668 - val_accuracy: 0.8000 - val_loss: 0.5848\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8563 - loss: 0.5181 - val_accuracy: 0.8000 - val_loss: 0.4951\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 0.4124 - val_accuracy: 0.8125 - val_loss: 0.4299\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8748 - loss: 0.3436 - val_accuracy: 0.8250 - val_loss: 0.3798\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.3147 - val_accuracy: 0.8875 - val_loss: 0.3417\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9031 - loss: 0.2774 - val_accuracy: 0.8750 - val_loss: 0.3159\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8958 - loss: 0.2839 - val_accuracy: 0.8875 - val_loss: 0.2955\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9036 - loss: 0.2595 - val_accuracy: 0.8875 - val_loss: 0.2858\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9093 - loss: 0.2439 - val_accuracy: 0.9125 - val_loss: 0.2736\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.2475 - val_accuracy: 0.9000 - val_loss: 0.2680\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9056 - loss: 0.2466 - val_accuracy: 0.9125 - val_loss: 0.2604\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9157 - loss: 0.2362 - val_accuracy: 0.9125 - val_loss: 0.2574\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8925 - loss: 0.2728 - val_accuracy: 0.9125 - val_loss: 0.2574\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8906 - loss: 0.2458 - val_accuracy: 0.9125 - val_loss: 0.2570\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9044 - loss: 0.2523 - val_accuracy: 0.9125 - val_loss: 0.2532\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9227 - loss: 0.2253 - val_accuracy: 0.9000 - val_loss: 0.2513\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9037 - loss: 0.2430 - val_accuracy: 0.9250 - val_loss: 0.2524\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9082 - loss: 0.2306 - val_accuracy: 0.9125 - val_loss: 0.2531\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9131 - loss: 0.2087 - val_accuracy: 0.9125 - val_loss: 0.2510\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9144 - loss: 0.2202 - val_accuracy: 0.9125 - val_loss: 0.2516\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2511 - val_accuracy: 0.9125 - val_loss: 0.2511\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9098 - loss: 0.2537 - val_accuracy: 0.9125 - val_loss: 0.2516\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9011 - loss: 0.2160 - val_accuracy: 0.9125 - val_loss: 0.2509\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9119 - loss: 0.2332 - val_accuracy: 0.9125 - val_loss: 0.2513\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9240 - loss: 0.2276 - val_accuracy: 0.9125 - val_loss: 0.2524\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9075 - loss: 0.2532 - val_accuracy: 0.9250 - val_loss: 0.2531\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9261 - loss: 0.2173 - val_accuracy: 0.9250 - val_loss: 0.2526\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8945 - loss: 0.2640 - val_accuracy: 0.9125 - val_loss: 0.2494\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9165 - loss: 0.2086 - val_accuracy: 0.9125 - val_loss: 0.2516\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9114 - loss: 0.2300 - val_accuracy: 0.9125 - val_loss: 0.2521\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9211 - loss: 0.2141 - val_accuracy: 0.9250 - val_loss: 0.2541\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9237 - loss: 0.2078 - val_accuracy: 0.9125 - val_loss: 0.2538\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8983 - loss: 0.2357 - val_accuracy: 0.9250 - val_loss: 0.2544\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9203 - loss: 0.2262 - val_accuracy: 0.9250 - val_loss: 0.2526\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9445 - loss: 0.1787 - val_accuracy: 0.9250 - val_loss: 0.2565\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9309 - loss: 0.2099 - val_accuracy: 0.9125 - val_loss: 0.2552\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9150 - loss: 0.2046 - val_accuracy: 0.9250 - val_loss: 0.2546\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.2152 - val_accuracy: 0.9250 - val_loss: 0.2554\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9201 - loss: 0.2146 - val_accuracy: 0.9125 - val_loss: 0.2558\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.2397 - val_accuracy: 0.9250 - val_loss: 0.2549\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9142 - loss: 0.2110 - val_accuracy: 0.9250 - val_loss: 0.2569\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.2471 - val_accuracy: 0.9250 - val_loss: 0.2562\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.1873 - val_accuracy: 0.9250 - val_loss: 0.2589\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9103 - loss: 0.2402 - val_accuracy: 0.9125 - val_loss: 0.2572\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.1850 - val_accuracy: 0.9250 - val_loss: 0.2586\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9145 - loss: 0.2160 - val_accuracy: 0.9250 - val_loss: 0.2586\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9141 - loss: 0.2075 - val_accuracy: 0.9250 - val_loss: 0.2581\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9189 - loss: 0.1879 - val_accuracy: 0.9250 - val_loss: 0.2573\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9170 - loss: 0.1951 - val_accuracy: 0.9250 - val_loss: 0.2629\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9220 - loss: 0.2044 - val_accuracy: 0.9250 - val_loss: 0.2596\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9045 - loss: 0.2230 - val_accuracy: 0.9250 - val_loss: 0.2604\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9333 - loss: 0.1864 - val_accuracy: 0.9250 - val_loss: 0.2608\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9463 - loss: 0.1635 - val_accuracy: 0.9250 - val_loss: 0.2617\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9226 - loss: 0.2241 - val_accuracy: 0.9250 - val_loss: 0.2627\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9330 - loss: 0.1686 - val_accuracy: 0.9250 - val_loss: 0.2625\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9280 - loss: 0.1920 - val_accuracy: 0.9125 - val_loss: 0.2635\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.1486 - val_accuracy: 0.9250 - val_loss: 0.2650\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9172 - loss: 0.2056 - val_accuracy: 0.9125 - val_loss: 0.2659\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9246 - loss: 0.1871 - val_accuracy: 0.9250 - val_loss: 0.2666\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1699 - val_accuracy: 0.9250 - val_loss: 0.2661\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9124 - loss: 0.1969 - val_accuracy: 0.9125 - val_loss: 0.2661\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8925 - loss: 0.2340 - val_accuracy: 0.9125 - val_loss: 0.2694\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.1783 - val_accuracy: 0.9125 - val_loss: 0.2693\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8995 - loss: 0.2218 - val_accuracy: 0.9000 - val_loss: 0.2713\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9239 - loss: 0.2059 - val_accuracy: 0.9250 - val_loss: 0.2699\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9253 - loss: 0.2000 - val_accuracy: 0.9125 - val_loss: 0.2692\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.1782 - val_accuracy: 0.9000 - val_loss: 0.2717\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9292 - loss: 0.1751 - val_accuracy: 0.9125 - val_loss: 0.2732\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8826 - loss: 0.2326 - val_accuracy: 0.9000 - val_loss: 0.2738\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9307 - loss: 0.1866 - val_accuracy: 0.9125 - val_loss: 0.2755\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9385 - loss: 0.1738 - val_accuracy: 0.9125 - val_loss: 0.2758\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.1874 - val_accuracy: 0.9000 - val_loss: 0.2760\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9070 - loss: 0.1934 - val_accuracy: 0.9000 - val_loss: 0.2769\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.1788 - val_accuracy: 0.9000 - val_loss: 0.2799\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9163 - loss: 0.2049 - val_accuracy: 0.9125 - val_loss: 0.2777\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9178 - loss: 0.1997 - val_accuracy: 0.9000 - val_loss: 0.2801\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9261 - loss: 0.1852 - val_accuracy: 0.9000 - val_loss: 0.2803\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9051 - loss: 0.2141 - val_accuracy: 0.9000 - val_loss: 0.2803\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9447 - loss: 0.1574 - val_accuracy: 0.9000 - val_loss: 0.2828\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9066 - loss: 0.2029 - val_accuracy: 0.9000 - val_loss: 0.2812\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9160 - loss: 0.1833 - val_accuracy: 0.9000 - val_loss: 0.2827\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9148 - loss: 0.2081 - val_accuracy: 0.9000 - val_loss: 0.2842\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9269 - loss: 0.1767 - val_accuracy: 0.9000 - val_loss: 0.2856\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.1774 - val_accuracy: 0.9000 - val_loss: 0.2851\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9198 - loss: 0.2077 - val_accuracy: 0.9000 - val_loss: 0.2869\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9247 - loss: 0.1902 - val_accuracy: 0.9000 - val_loss: 0.2878\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9298 - loss: 0.1768 - val_accuracy: 0.9000 - val_loss: 0.2900\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9168 - loss: 0.1914 - val_accuracy: 0.9000 - val_loss: 0.2876\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9093 - loss: 0.2206 - val_accuracy: 0.9000 - val_loss: 0.2912\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9307 - loss: 0.1799 - val_accuracy: 0.9000 - val_loss: 0.2907\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.1620 - val_accuracy: 0.9000 - val_loss: 0.2905\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.2015 - val_accuracy: 0.9000 - val_loss: 0.2929\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.1815 - val_accuracy: 0.9000 - val_loss: 0.2968\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9183 - loss: 0.2041 - val_accuracy: 0.9000 - val_loss: 0.2968\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9295 - loss: 0.1978 - val_accuracy: 0.9000 - val_loss: 0.2968\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9032 - loss: 0.2135 - val_accuracy: 0.9000 - val_loss: 0.2957\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.1685 - val_accuracy: 0.9000 - val_loss: 0.2971\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8983 - loss: 0.2264 - val_accuracy: 0.9000 - val_loss: 0.2983\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.1483 - val_accuracy: 0.9000 - val_loss: 0.2996\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1481 - val_accuracy: 0.9000 - val_loss: 0.3039\n"
     ]
    }
   ],
   "source": [
    "# How to solve the problem\n",
    "## point 1) reduce the complexity\n",
    "## point 2 ) In hidden layer, use Relu activation function\n",
    "# Vanishing Gradient problem occurs\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(128, activation='relu', input_dim=2))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01417f1c-00c4-4c34-bbee-f46cdb6d4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5661 - loss: 0.6727 - val_accuracy: 0.8125 - val_loss: 0.6015\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8114 - loss: 0.5585 - val_accuracy: 0.8000 - val_loss: 0.5253\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8596 - loss: 0.4696 - val_accuracy: 0.8125 - val_loss: 0.4650\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8099 - loss: 0.4345 - val_accuracy: 0.8000 - val_loss: 0.4157\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.3500 - val_accuracy: 0.8000 - val_loss: 0.3774\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8509 - loss: 0.3505 - val_accuracy: 0.8250 - val_loss: 0.3508\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8624 - loss: 0.3408 - val_accuracy: 0.8750 - val_loss: 0.3315\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8699 - loss: 0.3189 - val_accuracy: 0.8875 - val_loss: 0.3165\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8865 - loss: 0.2804 - val_accuracy: 0.9000 - val_loss: 0.3014\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8868 - loss: 0.2639 - val_accuracy: 0.8875 - val_loss: 0.2894\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9091 - loss: 0.2427 - val_accuracy: 0.8875 - val_loss: 0.2816\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8793 - loss: 0.2913 - val_accuracy: 0.8875 - val_loss: 0.2746\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.2742 - val_accuracy: 0.9125 - val_loss: 0.2689\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9159 - loss: 0.2484 - val_accuracy: 0.9000 - val_loss: 0.2646\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9216 - loss: 0.2169 - val_accuracy: 0.8875 - val_loss: 0.2615\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9023 - loss: 0.2627 - val_accuracy: 0.8875 - val_loss: 0.2617\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8799 - loss: 0.2887 - val_accuracy: 0.9125 - val_loss: 0.2575\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9122 - loss: 0.2400 - val_accuracy: 0.9125 - val_loss: 0.2562\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9046 - loss: 0.2445 - val_accuracy: 0.9125 - val_loss: 0.2541\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8972 - loss: 0.2554 - val_accuracy: 0.9125 - val_loss: 0.2531\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9114 - loss: 0.2625 - val_accuracy: 0.9125 - val_loss: 0.2526\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9219 - loss: 0.2266 - val_accuracy: 0.9125 - val_loss: 0.2518\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8994 - loss: 0.2278 - val_accuracy: 0.9125 - val_loss: 0.2512\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.2677 - val_accuracy: 0.9125 - val_loss: 0.2510\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9066 - loss: 0.2441 - val_accuracy: 0.9125 - val_loss: 0.2505\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8919 - loss: 0.2886 - val_accuracy: 0.9125 - val_loss: 0.2479\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9165 - loss: 0.2263 - val_accuracy: 0.9125 - val_loss: 0.2472\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9059 - loss: 0.2547 - val_accuracy: 0.9125 - val_loss: 0.2473\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8979 - loss: 0.2488 - val_accuracy: 0.9125 - val_loss: 0.2480\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.2508 - val_accuracy: 0.9125 - val_loss: 0.2480\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8651 - loss: 0.3283 - val_accuracy: 0.9125 - val_loss: 0.2476\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9048 - loss: 0.2698 - val_accuracy: 0.9125 - val_loss: 0.2470\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 0.2288 - val_accuracy: 0.9125 - val_loss: 0.2475\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.2176 - val_accuracy: 0.9125 - val_loss: 0.2459\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9255 - loss: 0.2033 - val_accuracy: 0.9125 - val_loss: 0.2457\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9095 - loss: 0.2229 - val_accuracy: 0.9250 - val_loss: 0.2460\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8982 - loss: 0.2929 - val_accuracy: 0.9125 - val_loss: 0.2467\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9034 - loss: 0.2546 - val_accuracy: 0.9250 - val_loss: 0.2467\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9100 - loss: 0.2291 - val_accuracy: 0.9250 - val_loss: 0.2462\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9048 - loss: 0.1926 - val_accuracy: 0.9250 - val_loss: 0.2461\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9037 - loss: 0.2521 - val_accuracy: 0.9250 - val_loss: 0.2459\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9107 - loss: 0.2147 - val_accuracy: 0.9250 - val_loss: 0.2460\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9106 - loss: 0.2505 - val_accuracy: 0.9250 - val_loss: 0.2453\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9166 - loss: 0.2435 - val_accuracy: 0.9250 - val_loss: 0.2448\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9031 - loss: 0.2212 - val_accuracy: 0.9250 - val_loss: 0.2452\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8958 - loss: 0.2728 - val_accuracy: 0.9250 - val_loss: 0.2456\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8874 - loss: 0.2822 - val_accuracy: 0.9250 - val_loss: 0.2454\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9283 - loss: 0.1934 - val_accuracy: 0.9250 - val_loss: 0.2453\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9224 - loss: 0.2229 - val_accuracy: 0.9250 - val_loss: 0.2455\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9004 - loss: 0.2431 - val_accuracy: 0.9250 - val_loss: 0.2455\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8978 - loss: 0.2375 - val_accuracy: 0.9250 - val_loss: 0.2458\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9237 - loss: 0.2212 - val_accuracy: 0.9250 - val_loss: 0.2464\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9367 - loss: 0.1929 - val_accuracy: 0.9250 - val_loss: 0.2469\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9317 - loss: 0.2046 - val_accuracy: 0.9250 - val_loss: 0.2470\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.1827 - val_accuracy: 0.9250 - val_loss: 0.2471\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.2390 - val_accuracy: 0.9250 - val_loss: 0.2470\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.2047 - val_accuracy: 0.9250 - val_loss: 0.2476\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.2441 - val_accuracy: 0.9250 - val_loss: 0.2476\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8930 - loss: 0.2748 - val_accuracy: 0.9250 - val_loss: 0.2477\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9230 - loss: 0.2106 - val_accuracy: 0.9250 - val_loss: 0.2478\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8977 - loss: 0.2776 - val_accuracy: 0.9250 - val_loss: 0.2480\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9053 - loss: 0.2437 - val_accuracy: 0.9250 - val_loss: 0.2485\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9207 - loss: 0.1990 - val_accuracy: 0.9250 - val_loss: 0.2487\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9230 - loss: 0.2209 - val_accuracy: 0.9250 - val_loss: 0.2495\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9284 - loss: 0.2021 - val_accuracy: 0.9250 - val_loss: 0.2500\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9246 - loss: 0.2048 - val_accuracy: 0.9250 - val_loss: 0.2502\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9242 - loss: 0.2044 - val_accuracy: 0.9250 - val_loss: 0.2505\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9260 - loss: 0.2344 - val_accuracy: 0.9250 - val_loss: 0.2515\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1948 - val_accuracy: 0.9250 - val_loss: 0.2507\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9315 - loss: 0.2297 - val_accuracy: 0.9250 - val_loss: 0.2508\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9252 - loss: 0.2142 - val_accuracy: 0.9250 - val_loss: 0.2513\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9097 - loss: 0.2328 - val_accuracy: 0.9250 - val_loss: 0.2514\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.2249 - val_accuracy: 0.9250 - val_loss: 0.2517\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9196 - loss: 0.2301 - val_accuracy: 0.9250 - val_loss: 0.2511\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9120 - loss: 0.2249 - val_accuracy: 0.9250 - val_loss: 0.2507\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9181 - loss: 0.2139 - val_accuracy: 0.9250 - val_loss: 0.2504\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9180 - loss: 0.1964 - val_accuracy: 0.9250 - val_loss: 0.2510\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.2248 - val_accuracy: 0.9250 - val_loss: 0.2515\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9176 - loss: 0.2235 - val_accuracy: 0.9250 - val_loss: 0.2515\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9194 - loss: 0.2324 - val_accuracy: 0.9250 - val_loss: 0.2520\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2509 - val_accuracy: 0.9250 - val_loss: 0.2522\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.2012 - val_accuracy: 0.9250 - val_loss: 0.2533\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9174 - loss: 0.2073 - val_accuracy: 0.9250 - val_loss: 0.2537\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9099 - loss: 0.2077 - val_accuracy: 0.9250 - val_loss: 0.2549\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.1891 - val_accuracy: 0.9125 - val_loss: 0.2554\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9388 - loss: 0.1773 - val_accuracy: 0.9125 - val_loss: 0.2560\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9256 - loss: 0.2171 - val_accuracy: 0.9125 - val_loss: 0.2563\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.2124 - val_accuracy: 0.9125 - val_loss: 0.2560\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2283 - val_accuracy: 0.9125 - val_loss: 0.2566\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9178 - loss: 0.2171 - val_accuracy: 0.9125 - val_loss: 0.2566\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9184 - loss: 0.1976 - val_accuracy: 0.9125 - val_loss: 0.2566\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.2049 - val_accuracy: 0.9250 - val_loss: 0.2569\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8904 - loss: 0.2416 - val_accuracy: 0.9250 - val_loss: 0.2573\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9069 - loss: 0.2087 - val_accuracy: 0.9250 - val_loss: 0.2577\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9047 - loss: 0.2104 - val_accuracy: 0.9250 - val_loss: 0.2578\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9245 - loss: 0.2044 - val_accuracy: 0.9250 - val_loss: 0.2587\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2213 - val_accuracy: 0.9250 - val_loss: 0.2582\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9294 - loss: 0.1795 - val_accuracy: 0.9250 - val_loss: 0.2583\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9196 - loss: 0.2190 - val_accuracy: 0.9250 - val_loss: 0.2581\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.2086 - val_accuracy: 0.9250 - val_loss: 0.2592\n"
     ]
    }
   ],
   "source": [
    "# using dropout\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(128, activation='relu', input_dim=2))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "798d90b9-3c8c-43ed-9ee0-e25d0e6c876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2118df51-fd9d-4f33-924f-dc2cfe8282ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4244 - loss: 0.7193 - val_accuracy: 0.8375 - val_loss: 0.6565\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6703 - loss: 0.6470 - val_accuracy: 0.8250 - val_loss: 0.6068\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8071 - loss: 0.5769 - val_accuracy: 0.8125 - val_loss: 0.5629\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.5311 - val_accuracy: 0.8125 - val_loss: 0.5225\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8483 - loss: 0.4912 - val_accuracy: 0.8250 - val_loss: 0.4837\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8500 - loss: 0.4395 - val_accuracy: 0.8250 - val_loss: 0.4474\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8420 - loss: 0.4361 - val_accuracy: 0.8125 - val_loss: 0.4195\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8643 - loss: 0.3933 - val_accuracy: 0.8375 - val_loss: 0.3960\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8397 - loss: 0.3703 - val_accuracy: 0.8625 - val_loss: 0.3753\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8687 - loss: 0.3849 - val_accuracy: 0.8625 - val_loss: 0.3575\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8872 - loss: 0.3647 - val_accuracy: 0.8750 - val_loss: 0.3454\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8696 - loss: 0.3309 - val_accuracy: 0.8875 - val_loss: 0.3335\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8471 - loss: 0.3685 - val_accuracy: 0.8875 - val_loss: 0.3244\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.2839 - val_accuracy: 0.9000 - val_loss: 0.3161\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8643 - loss: 0.3405 - val_accuracy: 0.9000 - val_loss: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8942 - loss: 0.3107 - val_accuracy: 0.8875 - val_loss: 0.2992\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9209 - loss: 0.2593 - val_accuracy: 0.8875 - val_loss: 0.2916\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8860 - loss: 0.3103 - val_accuracy: 0.8875 - val_loss: 0.2870\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8975 - loss: 0.2848 - val_accuracy: 0.8875 - val_loss: 0.2841\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8955 - loss: 0.2826 - val_accuracy: 0.8875 - val_loss: 0.2811\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8559 - loss: 0.3144 - val_accuracy: 0.8875 - val_loss: 0.2781\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.2329 - val_accuracy: 0.8875 - val_loss: 0.2760\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8813 - loss: 0.3326 - val_accuracy: 0.8875 - val_loss: 0.2726\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2653 - val_accuracy: 0.9000 - val_loss: 0.2686\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.2931 - val_accuracy: 0.9000 - val_loss: 0.2654\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9032 - loss: 0.2257 - val_accuracy: 0.9125 - val_loss: 0.2638\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9106 - loss: 0.2401 - val_accuracy: 0.9125 - val_loss: 0.2630\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.2545 - val_accuracy: 0.9125 - val_loss: 0.2616\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - loss: 0.2227 - val_accuracy: 0.9125 - val_loss: 0.2618\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9172 - loss: 0.2440 - val_accuracy: 0.9125 - val_loss: 0.2609\n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9108 - loss: 0.2415 - val_accuracy: 0.9000 - val_loss: 0.2586\n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9129 - loss: 0.2800 - val_accuracy: 0.9125 - val_loss: 0.2575\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9029 - loss: 0.2517 - val_accuracy: 0.9125 - val_loss: 0.2577\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9073 - loss: 0.2773 - val_accuracy: 0.9125 - val_loss: 0.2584\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8639 - loss: 0.2932 - val_accuracy: 0.9125 - val_loss: 0.2575\n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9277 - loss: 0.2226 - val_accuracy: 0.9125 - val_loss: 0.2566\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.2567 - val_accuracy: 0.9125 - val_loss: 0.2548\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9090 - loss: 0.2506 - val_accuracy: 0.9125 - val_loss: 0.2540\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9374 - loss: 0.2065 - val_accuracy: 0.9125 - val_loss: 0.2535\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8959 - loss: 0.2490 - val_accuracy: 0.9125 - val_loss: 0.2539\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8720 - loss: 0.3184 - val_accuracy: 0.9125 - val_loss: 0.2545\n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8915 - loss: 0.2816 - val_accuracy: 0.9125 - val_loss: 0.2540\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9021 - loss: 0.2455 - val_accuracy: 0.9125 - val_loss: 0.2530\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9317 - loss: 0.2241 - val_accuracy: 0.9125 - val_loss: 0.2529\n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9348 - loss: 0.2209 - val_accuracy: 0.9125 - val_loss: 0.2519\n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9002 - loss: 0.2519 - val_accuracy: 0.9125 - val_loss: 0.2516\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8919 - loss: 0.2626 - val_accuracy: 0.9125 - val_loss: 0.2512\n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.2633 - val_accuracy: 0.9250 - val_loss: 0.2508\n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9158 - loss: 0.2405 - val_accuracy: 0.9125 - val_loss: 0.2519\n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9170 - loss: 0.2463 - val_accuracy: 0.9250 - val_loss: 0.2507\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(64, activation='relu', input_dim=2))\n",
    "model3.add(Dropout(0.5))\n",
    "#model3.add(BatchNormalization())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "#model3.add(BatchNormalization())\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d610-0350-4d7b-9860-bcb4d1f49c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "659c15fa-65ad-4801-b69b-eb8c2166663e",
   "metadata": {},
   "source": [
    "# Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cbfa297-0092-4105-b3d9-57471c43772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kumar sundram\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96dd7f8b-0893-48d7-bcae-1860149412d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the torch library followed by torch.nn library as nn\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77dab45d-9cde-4eef-ae90-34e9aedf0337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  2., -1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign inputs to the neuron\n",
    "# Inputs to the neuron - we have used random values here\n",
    "inputs = torch.tensor([3.0,2.0, -1.0])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f5c2c1c-a234-40ac-bc48-6b7f09c00282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neuron with 3 features and 1 output\n",
    "neuron = nn.Linear(in_features = 3, out_features=1)\n",
    "output = neuron(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20d5d720-e768-4504-8f96-b89f7504dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5647], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dffe0af-0c32-4a9f-b34d-e185e4133989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4175,  0.1426, -0.1370]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(neuron.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e2d0d7-d208-42b4-a634-363c0f249374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1100], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(neuron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c111f83-8c38-423a-a7af-617b51d73c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUMAR SUNDRAM\\AppData\\Local\\Temp\\ipykernel_17740\\1648406665.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3679.)\n",
      "  neuron.weight@inputs.T + neuron.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.5647], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formula for the final output of the neuron\n",
    "neuron.weight@inputs.T + neuron.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effec42c-e6fb-4faf-a632-545b09045b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd3d9e4-5b6d-4433-b1f1-ea70742b31a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KUMAR SUNDRAM\\\\Desktop\\\\Adv AI - 1st June 2024\\\\DNN'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prodigy_University_Dataset dataset - using Pytorch/torch library\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b447d-982d-4b1d-a2d4-3b11c3123227",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prodigy University Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f35c1f4-5ee6-47c4-989f-49b7e04ab895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_sum</th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>fy_gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sat_sum  hs_gpa  fy_gpa\n",
       "0      508    3.40    3.18\n",
       "1      488    4.00    3.33\n",
       "2      464    3.75    3.25\n",
       "3      380    3.75    2.42\n",
       "4      428    4.00    2.63"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Prodigy University Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8a03ff4-4e6c-4bc0-9a9c-1300eff76772",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['sat_sum', 'hs_gpa']].values\n",
    "y = data['fy_gpa'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07472483-2721-446d-9e08-f284e7264ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c102a718-f02e-442c-bde1-d39aebcb4aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09e0e407-73c5-4c00-a328-d5601daf803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "793081e6-60c1-4bea-931e-518f5648e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68152739-ec0f-46eb-bb09-4b6503e93ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61475533,  0.58852578],\n",
       "       [-1.40573678,  0.40195133],\n",
       "       [-0.43031692, -0.90406983],\n",
       "       ...,\n",
       "       [ 1.79921419,  1.52139804],\n",
       "       [-1.68442817, -0.53092092],\n",
       "       [ 0.26641155,  0.40195133]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4302f635-c076-4978-90b6-2edbb2f964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e61313ae-0b45-4611-8ed7-693951ff2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ca0ce79-2409-4623-ab3f-f8b89218ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the MLP model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2,2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2,1)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64ab9433-2f60-4613-ab67-dcda8dc6daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8263a35f-b2de-460c-80e2-27587368c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Building the MLP model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,5)  \n",
    "    nn.Softmax()\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cea052e-4de9-420a-8ced-07670a9547ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5041],\n",
      "        [0.5133],\n",
      "        [0.6015],\n",
      "        [0.4740],\n",
      "        [0.6337],\n",
      "        [0.4389],\n",
      "        [0.3605],\n",
      "        [0.3764],\n",
      "        [0.7173],\n",
      "        [0.4114],\n",
      "        [0.3801],\n",
      "        [0.5060],\n",
      "        [0.5620],\n",
      "        [0.6005],\n",
      "        [0.6918],\n",
      "        [0.5690],\n",
      "        [0.3991],\n",
      "        [0.3722],\n",
      "        [0.6279],\n",
      "        [0.7251],\n",
      "        [0.6128],\n",
      "        [0.4264],\n",
      "        [0.4156],\n",
      "        [0.5446],\n",
      "        [0.4477],\n",
      "        [0.3744],\n",
      "        [0.7179],\n",
      "        [0.6131],\n",
      "        [0.5160],\n",
      "        [0.5182],\n",
      "        [0.5649],\n",
      "        [0.5248],\n",
      "        [0.5126],\n",
      "        [0.4815],\n",
      "        [0.3372],\n",
      "        [0.3412],\n",
      "        [0.4114],\n",
      "        [0.5366],\n",
      "        [0.3391],\n",
      "        [0.5759],\n",
      "        [0.4236],\n",
      "        [0.7210],\n",
      "        [0.4415],\n",
      "        [0.4872],\n",
      "        [0.6356],\n",
      "        [0.4483],\n",
      "        [0.6823],\n",
      "        [0.3990],\n",
      "        [0.3429],\n",
      "        [0.3967],\n",
      "        [0.4261],\n",
      "        [0.3007],\n",
      "        [0.4550],\n",
      "        [0.6641],\n",
      "        [0.5779],\n",
      "        [0.5379],\n",
      "        [0.4062],\n",
      "        [0.5168],\n",
      "        [0.4111],\n",
      "        [0.3548],\n",
      "        [0.5572],\n",
      "        [0.5433],\n",
      "        [0.5658],\n",
      "        [0.4929],\n",
      "        [0.5581],\n",
      "        [0.5270],\n",
      "        [0.6459],\n",
      "        [0.6191],\n",
      "        [0.4787],\n",
      "        [0.4415],\n",
      "        [0.4187],\n",
      "        [0.3521],\n",
      "        [0.3858],\n",
      "        [0.3138],\n",
      "        [0.6905],\n",
      "        [0.6547],\n",
      "        [0.5594],\n",
      "        [0.4041],\n",
      "        [0.5131],\n",
      "        [0.4777],\n",
      "        [0.3720],\n",
      "        [0.4749],\n",
      "        [0.3190],\n",
      "        [0.5299],\n",
      "        [0.5624],\n",
      "        [0.6575],\n",
      "        [0.5857],\n",
      "        [0.5525],\n",
      "        [0.3768],\n",
      "        [0.3980],\n",
      "        [0.3535],\n",
      "        [0.5543],\n",
      "        [0.4189],\n",
      "        [0.6221],\n",
      "        [0.5073],\n",
      "        [0.4446],\n",
      "        [0.4014],\n",
      "        [0.3703],\n",
      "        [0.3703],\n",
      "        [0.7284],\n",
      "        [0.5620],\n",
      "        [0.6752],\n",
      "        [0.4393],\n",
      "        [0.3541],\n",
      "        [0.3555],\n",
      "        [0.3613],\n",
      "        [0.6480],\n",
      "        [0.4666],\n",
      "        [0.6210],\n",
      "        [0.4363],\n",
      "        [0.6611],\n",
      "        [0.4089],\n",
      "        [0.4415],\n",
      "        [0.4601],\n",
      "        [0.3468],\n",
      "        [0.6308],\n",
      "        [0.6157],\n",
      "        [0.5131],\n",
      "        [0.6102],\n",
      "        [0.4929],\n",
      "        [0.3651],\n",
      "        [0.4830],\n",
      "        [0.6139],\n",
      "        [0.3757],\n",
      "        [0.5620],\n",
      "        [0.4365],\n",
      "        [0.5611],\n",
      "        [0.6287],\n",
      "        [0.5387],\n",
      "        [0.6040],\n",
      "        [0.4086],\n",
      "        [0.5671],\n",
      "        [0.3528],\n",
      "        [0.3138],\n",
      "        [0.3965],\n",
      "        [0.3791],\n",
      "        [0.5985],\n",
      "        [0.4547],\n",
      "        [0.3948],\n",
      "        [0.4112],\n",
      "        [0.4828],\n",
      "        [0.5868],\n",
      "        [0.3856],\n",
      "        [0.7141],\n",
      "        [0.4997],\n",
      "        [0.6033],\n",
      "        [0.5484],\n",
      "        [0.4160],\n",
      "        [0.5520],\n",
      "        [0.4389],\n",
      "        [0.6641],\n",
      "        [0.5690],\n",
      "        [0.3917],\n",
      "        [0.5658],\n",
      "        [0.6446],\n",
      "        [0.3297],\n",
      "        [0.6356],\n",
      "        [0.6752],\n",
      "        [0.5739],\n",
      "        [0.3392],\n",
      "        [0.4523],\n",
      "        [0.6404],\n",
      "        [0.5706],\n",
      "        [0.4917],\n",
      "        [0.3316],\n",
      "        [0.4547],\n",
      "        [0.5921],\n",
      "        [0.4709],\n",
      "        [0.5102],\n",
      "        [0.3190],\n",
      "        [0.3528],\n",
      "        [0.5270],\n",
      "        [0.5000],\n",
      "        [0.5535],\n",
      "        [0.5087],\n",
      "        [0.3757],\n",
      "        [0.4800],\n",
      "        [0.5684],\n",
      "        [0.4237],\n",
      "        [0.5475],\n",
      "        [0.4311],\n",
      "        [0.3334],\n",
      "        [0.4884],\n",
      "        [0.7703],\n",
      "        [0.5190],\n",
      "        [0.4337],\n",
      "        [0.3208],\n",
      "        [0.6201],\n",
      "        [0.3757],\n",
      "        [0.5926],\n",
      "        [0.6545],\n",
      "        [0.4958],\n",
      "        [0.4312],\n",
      "        [0.4901],\n",
      "        [0.6133],\n",
      "        [0.6181],\n",
      "        [0.5124],\n",
      "        [0.5720],\n",
      "        [0.4802],\n",
      "        [0.4136],\n",
      "        [0.4874],\n",
      "        [0.4188],\n",
      "        [0.7128],\n",
      "        [0.3703],\n",
      "        [0.5211],\n",
      "        [0.5543],\n",
      "        [0.6064],\n",
      "        [0.3872],\n",
      "        [0.5073],\n",
      "        [0.4569],\n",
      "        [0.3576],\n",
      "        [0.6697],\n",
      "        [0.3714],\n",
      "        [0.4896],\n",
      "        [0.5809],\n",
      "        [0.4494],\n",
      "        [0.4607],\n",
      "        [0.6897],\n",
      "        [0.4917],\n",
      "        [0.4604],\n",
      "        [0.4042],\n",
      "        [0.4339],\n",
      "        [0.4339],\n",
      "        [0.4721],\n",
      "        [0.3468],\n",
      "        [0.4631],\n",
      "        [0.4261],\n",
      "        [0.5789],\n",
      "        [0.5809],\n",
      "        [0.4018],\n",
      "        [0.4235],\n",
      "        [0.6064],\n",
      "        [0.6588],\n",
      "        [0.5966],\n",
      "        [0.5205],\n",
      "        [0.6094],\n",
      "        [0.4731],\n",
      "        [0.3225],\n",
      "        [0.5611],\n",
      "        [0.6122],\n",
      "        [0.3391],\n",
      "        [0.6004],\n",
      "        [0.4874],\n",
      "        [0.6162],\n",
      "        [0.5622],\n",
      "        [0.3923],\n",
      "        [0.3190],\n",
      "        [0.6689],\n",
      "        [0.7681],\n",
      "        [0.4958],\n",
      "        [0.4393],\n",
      "        [0.4086],\n",
      "        [0.6093],\n",
      "        [0.3672],\n",
      "        [0.5131],\n",
      "        [0.5851],\n",
      "        [0.4422],\n",
      "        [0.4387],\n",
      "        [0.5479],\n",
      "        [0.3279],\n",
      "        [0.4987],\n",
      "        [0.4465],\n",
      "        [0.5701],\n",
      "        [0.4795],\n",
      "        [0.4611],\n",
      "        [0.6789],\n",
      "        [0.3225],\n",
      "        [0.4744],\n",
      "        [0.3831],\n",
      "        [0.6498],\n",
      "        [0.3880],\n",
      "        [0.6131],\n",
      "        [0.5631],\n",
      "        [0.4286],\n",
      "        [0.3613],\n",
      "        [0.4441],\n",
      "        [0.5471],\n",
      "        [0.4844],\n",
      "        [0.5226],\n",
      "        [0.6509],\n",
      "        [0.3631],\n",
      "        [0.3429],\n",
      "        [0.4066],\n",
      "        [0.5953],\n",
      "        [0.4713],\n",
      "        [0.4846],\n",
      "        [0.6261],\n",
      "        [0.6389],\n",
      "        [0.7406],\n",
      "        [0.5256],\n",
      "        [0.6332],\n",
      "        [0.5637],\n",
      "        [0.4211],\n",
      "        [0.4286],\n",
      "        [0.5015],\n",
      "        [0.7500],\n",
      "        [0.4089],\n",
      "        [0.6187],\n",
      "        [0.5153],\n",
      "        [0.4580],\n",
      "        [0.4851],\n",
      "        [0.6585],\n",
      "        [0.4314],\n",
      "        [0.6315],\n",
      "        [0.5946],\n",
      "        [0.4367],\n",
      "        [0.3639],\n",
      "        [0.5551],\n",
      "        [0.3261],\n",
      "        [0.4391],\n",
      "        [0.4709],\n",
      "        [0.4972],\n",
      "        [0.5679],\n",
      "        [0.3833],\n",
      "        [0.3264],\n",
      "        [0.4162],\n",
      "        [0.4693],\n",
      "        [0.4917],\n",
      "        [0.5073],\n",
      "        [0.3541],\n",
      "        [0.5560],\n",
      "        [0.6274],\n",
      "        [0.4236],\n",
      "        [0.3766],\n",
      "        [0.4391],\n",
      "        [0.6289],\n",
      "        [0.3889],\n",
      "        [0.5436],\n",
      "        [0.6122],\n",
      "        [0.6414],\n",
      "        [0.3813],\n",
      "        [0.5057],\n",
      "        [0.3474],\n",
      "        [0.5688],\n",
      "        [0.3698],\n",
      "        [0.5649],\n",
      "        [0.4136],\n",
      "        [0.6641],\n",
      "        [0.4805],\n",
      "        [0.4063],\n",
      "        [0.4483],\n",
      "        [0.3372],\n",
      "        [0.4527],\n",
      "        [0.3746],\n",
      "        [0.5160],\n",
      "        [0.4496],\n",
      "        [0.3353],\n",
      "        [0.3225],\n",
      "        [0.4389],\n",
      "        [0.4138],\n",
      "        [0.5735],\n",
      "        [0.5700],\n",
      "        [0.6276],\n",
      "        [0.3156],\n",
      "        [0.4815],\n",
      "        [0.4598],\n",
      "        [0.3594],\n",
      "        [0.4413],\n",
      "        [0.6534],\n",
      "        [0.5572],\n",
      "        [0.4313],\n",
      "        [0.6133],\n",
      "        [0.5713],\n",
      "        [0.6201],\n",
      "        [0.4823],\n",
      "        [0.3746],\n",
      "        [0.4662],\n",
      "        [0.6010],\n",
      "        [0.4185],\n",
      "        [0.5748],\n",
      "        [0.5513],\n",
      "        [0.5073],\n",
      "        [0.4810],\n",
      "        [0.4703],\n",
      "        [0.6532],\n",
      "        [0.4971],\n",
      "        [0.3573],\n",
      "        [0.5759],\n",
      "        [0.6404],\n",
      "        [0.5885],\n",
      "        [0.5428],\n",
      "        [0.3735],\n",
      "        [0.5111],\n",
      "        [0.4636],\n",
      "        [0.5484],\n",
      "        [0.4439],\n",
      "        [0.4113],\n",
      "        [0.6045],\n",
      "        [0.7614],\n",
      "        [0.5454],\n",
      "        [0.5809],\n",
      "        [0.5233],\n",
      "        [0.3845],\n",
      "        [0.4974],\n",
      "        [0.3173],\n",
      "        [0.4012],\n",
      "        [0.6122],\n",
      "        [0.5270],\n",
      "        [0.5175],\n",
      "        [0.3889],\n",
      "        [0.3353],\n",
      "        [0.3757],\n",
      "        [0.5387],\n",
      "        [0.6391],\n",
      "        [0.6705],\n",
      "        [0.5631],\n",
      "        [0.5661],\n",
      "        [0.3512],\n",
      "        [0.4136],\n",
      "        [0.6715],\n",
      "        [0.6240],\n",
      "        [0.5777],\n",
      "        [0.5022],\n",
      "        [0.6113],\n",
      "        [0.3568],\n",
      "        [0.5917],\n",
      "        [0.6613],\n",
      "        [0.4917],\n",
      "        [0.5534],\n",
      "        [0.6073],\n",
      "        [0.5044],\n",
      "        [0.7082],\n",
      "        [0.4526],\n",
      "        [0.5143],\n",
      "        [0.5089],\n",
      "        [0.5739],\n",
      "        [0.3514],\n",
      "        [0.5513],\n",
      "        [0.7235],\n",
      "        [0.3639],\n",
      "        [0.7413],\n",
      "        [0.5907],\n",
      "        [0.4089],\n",
      "        [0.4746],\n",
      "        [0.4395],\n",
      "        [0.3568],\n",
      "        [0.3105],\n",
      "        [0.4441],\n",
      "        [0.3509],\n",
      "        [0.3713],\n",
      "        [0.4362],\n",
      "        [0.3996],\n",
      "        [0.3948],\n",
      "        [0.3449],\n",
      "        [0.4337],\n",
      "        [0.5534],\n",
      "        [0.7582],\n",
      "        [0.6834],\n",
      "        [0.6878],\n",
      "        [0.4160],\n",
      "        [0.4664],\n",
      "        [0.3722],\n",
      "        [0.4286],\n",
      "        [0.3561],\n",
      "        [0.4915],\n",
      "        [0.7546],\n",
      "        [0.5297],\n",
      "        [0.2991],\n",
      "        [0.5720],\n",
      "        [0.3787],\n",
      "        [0.5395],\n",
      "        [0.6245],\n",
      "        [0.4958],\n",
      "        [0.6613],\n",
      "        [0.7056],\n",
      "        [0.3316],\n",
      "        [0.5620],\n",
      "        [0.5828],\n",
      "        [0.3989],\n",
      "        [0.7029],\n",
      "        [0.3930],\n",
      "        [0.4521],\n",
      "        [0.4856],\n",
      "        [0.7389],\n",
      "        [0.3279],\n",
      "        [0.4664],\n",
      "        [0.5307],\n",
      "        [0.6452],\n",
      "        [0.6471],\n",
      "        [0.7220],\n",
      "        [0.6230],\n",
      "        [0.5640],\n",
      "        [0.4821],\n",
      "        [0.2960],\n",
      "        [0.6912],\n",
      "        [0.3691],\n",
      "        [0.3644],\n",
      "        [0.4607],\n",
      "        [0.6500],\n",
      "        [0.6172],\n",
      "        [0.3764],\n",
      "        [0.4337],\n",
      "        [0.4188],\n",
      "        [0.4872],\n",
      "        [0.5616],\n",
      "        [0.4574],\n",
      "        [0.4136],\n",
      "        [0.3297],\n",
      "        [0.6142],\n",
      "        [0.4494],\n",
      "        [0.5887],\n",
      "        [0.6575],\n",
      "        [0.4415],\n",
      "        [0.6123],\n",
      "        [0.5944],\n",
      "        [0.4019],\n",
      "        [0.3744],\n",
      "        [0.3373],\n",
      "        [0.5015],\n",
      "        [0.3391],\n",
      "        [0.6705],\n",
      "        [0.6553],\n",
      "        [0.5985],\n",
      "        [0.4800],\n",
      "        [0.4607],\n",
      "        [0.5729],\n",
      "        [0.3415],\n",
      "        [0.3735],\n",
      "        [0.4210],\n",
      "        [0.5713],\n",
      "        [0.5807],\n",
      "        [0.7724],\n",
      "        [0.4091],\n",
      "        [0.4828],\n",
      "        [0.4337],\n",
      "        [0.5953],\n",
      "        [0.3919],\n",
      "        [0.4049],\n",
      "        [0.7582],\n",
      "        [0.5382],\n",
      "        [0.4162],\n",
      "        [0.5462],\n",
      "        [0.5102],\n",
      "        [0.6785],\n",
      "        [0.3592],\n",
      "        [0.5131],\n",
      "        [0.6074],\n",
      "        [0.5779],\n",
      "        [0.5718],\n",
      "        [0.4137],\n",
      "        [0.5974],\n",
      "        [0.3391],\n",
      "        [0.3532],\n",
      "        [0.4872],\n",
      "        [0.5720],\n",
      "        [0.4547],\n",
      "        [0.6958],\n",
      "        [0.4210],\n",
      "        [0.4312],\n",
      "        [0.4598],\n",
      "        [0.6210],\n",
      "        [0.5887],\n",
      "        [0.6123],\n",
      "        [0.5867],\n",
      "        [0.4774],\n",
      "        [0.7582],\n",
      "        [0.4991],\n",
      "        [0.3973],\n",
      "        [0.4685],\n",
      "        [0.4261],\n",
      "        [0.5160],\n",
      "        [0.3429],\n",
      "        [0.4363],\n",
      "        [0.3739],\n",
      "        [0.6555],\n",
      "        [0.6613],\n",
      "        [0.4818],\n",
      "        [0.6385],\n",
      "        [0.5534],\n",
      "        [0.6962],\n",
      "        [0.4560],\n",
      "        [0.5089],\n",
      "        [0.4499],\n",
      "        [0.5602],\n",
      "        [0.5358],\n",
      "        [0.4917],\n",
      "        [0.5095],\n",
      "        [0.5944],\n",
      "        [0.3889],\n",
      "        [0.5837],\n",
      "        [0.4235],\n",
      "        [0.6182],\n",
      "        [0.6650],\n",
      "        [0.5936],\n",
      "        [0.4395],\n",
      "        [0.4844],\n",
      "        [0.3923],\n",
      "        [0.4607],\n",
      "        [0.6462],\n",
      "        [0.4666],\n",
      "        [0.6724],\n",
      "        [0.5102],\n",
      "        [0.5768],\n",
      "        [0.5150],\n",
      "        [0.4593],\n",
      "        [0.3714],\n",
      "        [0.6250],\n",
      "        [0.4261],\n",
      "        [0.4389],\n",
      "        [0.4889],\n",
      "        [0.5652],\n",
      "        [0.5424],\n",
      "        [0.6063],\n",
      "        [0.5907],\n",
      "        [0.5602],\n",
      "        [0.4830],\n",
      "        [0.3555],\n",
      "        [0.4160],\n",
      "        [0.6837],\n",
      "        [0.6332],\n",
      "        [0.6269],\n",
      "        [0.6583],\n",
      "        [0.5620],\n",
      "        [0.7523],\n",
      "        [0.7166],\n",
      "        [0.3698],\n",
      "        [0.6556],\n",
      "        [0.5530],\n",
      "        [0.3995],\n",
      "        [0.4441],\n",
      "        [0.6040],\n",
      "        [0.5446],\n",
      "        [0.5095],\n",
      "        [0.5003],\n",
      "        [0.4634],\n",
      "        [0.6201],\n",
      "        [0.5395],\n",
      "        [0.6162],\n",
      "        [0.6356],\n",
      "        [0.4363],\n",
      "        [0.4777],\n",
      "        [0.5102],\n",
      "        [0.6394],\n",
      "        [0.3468],\n",
      "        [0.3630],\n",
      "        [0.5366],\n",
      "        [0.6878],\n",
      "        [0.5917],\n",
      "        [0.3840],\n",
      "        [0.6327],\n",
      "        [0.5411],\n",
      "        [0.3468],\n",
      "        [0.4286],\n",
      "        [0.4468],\n",
      "        [0.4185],\n",
      "        [0.5258],\n",
      "        [0.4709],\n",
      "        [0.4805],\n",
      "        [0.4362],\n",
      "        [0.5868],\n",
      "        [0.5661],\n",
      "        [0.3980],\n",
      "        [0.5395],\n",
      "        [0.4363],\n",
      "        [0.5556],\n",
      "        [0.6905],\n",
      "        [0.3879],\n",
      "        [0.4501],\n",
      "        [0.4387],\n",
      "        [0.4261],\n",
      "        [0.5649],\n",
      "        [0.3714],\n",
      "        [0.5867],\n",
      "        [0.4363],\n",
      "        [0.5649],\n",
      "        [0.4642],\n",
      "        [0.4391],\n",
      "        [0.3508],\n",
      "        [0.5902],\n",
      "        [0.6035],\n",
      "        [0.4851],\n",
      "        [0.3636],\n",
      "        [0.6240],\n",
      "        [0.6545],\n",
      "        [0.5935],\n",
      "        [0.3946],\n",
      "        [0.3693],\n",
      "        [0.6537],\n",
      "        [0.3990],\n",
      "        [0.3919],\n",
      "        [0.6361],\n",
      "        [0.3693],\n",
      "        [0.3735],\n",
      "        [0.5475],\n",
      "        [0.4858],\n",
      "        [0.5953],\n",
      "        [0.3693],\n",
      "        [0.5454],\n",
      "        [0.4336],\n",
      "        [0.4929],\n",
      "        [0.6442],\n",
      "        [0.7377],\n",
      "        [0.5868],\n",
      "        [0.5109],\n",
      "        [0.4815],\n",
      "        [0.6958],\n",
      "        [0.5620],\n",
      "        [0.3791],\n",
      "        [0.6770],\n",
      "        [0.4607],\n",
      "        [0.7595],\n",
      "        [0.5598],\n",
      "        [0.3279],\n",
      "        [0.7170],\n",
      "        [0.3934],\n",
      "        [0.4496],\n",
      "        [0.3474],\n",
      "        [0.4709],\n",
      "        [0.6471],\n",
      "        [0.5611],\n",
      "        [0.6865],\n",
      "        [0.4607],\n",
      "        [0.3088],\n",
      "        [0.4917],\n",
      "        [0.4441],\n",
      "        [0.3334],\n",
      "        [0.5285],\n",
      "        [0.6467],\n",
      "        [0.4496],\n",
      "        [0.4468],\n",
      "        [0.5855],\n",
      "        [0.4971],\n",
      "        [0.3867],\n",
      "        [0.3840],\n",
      "        [0.6356],\n",
      "        [0.6385],\n",
      "        [0.6063],\n",
      "        [0.3925],\n",
      "        [0.4073],\n",
      "        [0.5379],\n",
      "        [0.3903],\n",
      "        [0.5679],\n",
      "        [0.4587],\n",
      "        [0.4138],\n",
      "        [0.3925],\n",
      "        [0.6033],\n",
      "        [0.4065],\n",
      "        [0.6015],\n",
      "        [0.4872],\n",
      "        [0.3316],\n",
      "        [0.4556],\n",
      "        [0.6641],\n",
      "        [0.6413],\n",
      "        [0.5015],\n",
      "        [0.4137],\n",
      "        [0.7437],\n",
      "        [0.6211],\n",
      "        [0.4625],\n",
      "        [0.3509],\n",
      "        [0.5307],\n",
      "        [0.3639],\n",
      "        [0.6394],\n",
      "        [0.6621],\n",
      "        [0.4239],\n",
      "        [0.5697],\n",
      "        [0.3372],\n",
      "        [0.3835],\n",
      "        [0.4598],\n",
      "        [0.3966],\n",
      "        [0.3594],\n",
      "        [0.4468],\n",
      "        [0.4691],\n",
      "        [0.3651],\n",
      "        [0.5667],\n",
      "        [0.4018],\n",
      "        [0.5725],\n",
      "        [0.6005],\n",
      "        [0.5611],\n",
      "        [0.3468],\n",
      "        [0.5287],\n",
      "        [0.2960],\n",
      "        [0.4262],\n",
      "        [0.3854],\n",
      "        [0.6705],\n",
      "        [0.3589],\n",
      "        [0.5649],\n",
      "        [0.4574],\n",
      "        [0.3225],\n",
      "        [0.6103],\n",
      "        [0.5681],\n",
      "        [0.3353],\n",
      "        [0.5981],\n",
      "        [0.4838],\n",
      "        [0.4449],\n",
      "        [0.4494],\n",
      "        [0.3568],\n",
      "        [0.4041],\n",
      "        [0.5114],\n",
      "        [0.5892],\n",
      "        [0.5471],\n",
      "        [0.4336],\n",
      "        [0.5513],\n",
      "        [0.3023],\n",
      "        [0.3528],\n",
      "        [0.4592],\n",
      "        [0.3261],\n",
      "        [0.4261],\n",
      "        [0.3208],\n",
      "        [0.6171],\n",
      "        [0.4470]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward propagation\n",
    "preds_train = model(x_train_tensor)\n",
    "preds_test = model(x_test_tensor)\n",
    "print(preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dbce418-95a6-40bc-8e89-a5e66d578680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5346],\n",
      "        [0.6309],\n",
      "        [0.6624],\n",
      "        [0.4118],\n",
      "        [0.5280],\n",
      "        [0.5045],\n",
      "        [0.4518],\n",
      "        [0.6707],\n",
      "        [0.4452],\n",
      "        [0.3989],\n",
      "        [0.7343],\n",
      "        [0.6602],\n",
      "        [0.4945],\n",
      "        [0.5015],\n",
      "        [0.5917],\n",
      "        [0.3754],\n",
      "        [0.6835],\n",
      "        [0.5856],\n",
      "        [0.3879],\n",
      "        [0.4916],\n",
      "        [0.4471],\n",
      "        [0.6614],\n",
      "        [0.4951],\n",
      "        [0.4056],\n",
      "        [0.3823],\n",
      "        [0.5456],\n",
      "        [0.5334],\n",
      "        [0.4622],\n",
      "        [0.4545],\n",
      "        [0.5855],\n",
      "        [0.4909],\n",
      "        [0.3161],\n",
      "        [0.4743],\n",
      "        [0.6393],\n",
      "        [0.4093],\n",
      "        [0.7656],\n",
      "        [0.6396],\n",
      "        [0.5975],\n",
      "        [0.4997],\n",
      "        [0.4957],\n",
      "        [0.6950],\n",
      "        [0.3385],\n",
      "        [0.6162],\n",
      "        [0.6458],\n",
      "        [0.4945],\n",
      "        [0.4912],\n",
      "        [0.3569],\n",
      "        [0.4105],\n",
      "        [0.5669],\n",
      "        [0.3887],\n",
      "        [0.5562],\n",
      "        [0.7442],\n",
      "        [0.3233],\n",
      "        [0.6511],\n",
      "        [0.4452],\n",
      "        [0.3765],\n",
      "        [0.3308],\n",
      "        [0.3598],\n",
      "        [0.6214],\n",
      "        [0.4266],\n",
      "        [0.5765],\n",
      "        [0.4292],\n",
      "        [0.5676],\n",
      "        [0.5406],\n",
      "        [0.5320],\n",
      "        [0.3720],\n",
      "        [0.4312],\n",
      "        [0.4168],\n",
      "        [0.4589],\n",
      "        [0.5290],\n",
      "        [0.3662],\n",
      "        [0.3902],\n",
      "        [0.7786],\n",
      "        [0.4398],\n",
      "        [0.5581],\n",
      "        [0.5207],\n",
      "        [0.4928],\n",
      "        [0.3686],\n",
      "        [0.6344],\n",
      "        [0.3562],\n",
      "        [0.6511],\n",
      "        [0.4093],\n",
      "        [0.7085],\n",
      "        [0.3289],\n",
      "        [0.4594],\n",
      "        [0.4348],\n",
      "        [0.6142],\n",
      "        [0.4085],\n",
      "        [0.3852],\n",
      "        [0.4452],\n",
      "        [0.3856],\n",
      "        [0.6393],\n",
      "        [0.6617],\n",
      "        [0.3233],\n",
      "        [0.3486],\n",
      "        [0.3654],\n",
      "        [0.6248],\n",
      "        [0.3346],\n",
      "        [0.5673],\n",
      "        [0.5030],\n",
      "        [0.5190],\n",
      "        [0.3405],\n",
      "        [0.6180],\n",
      "        [0.4458],\n",
      "        [0.4452],\n",
      "        [0.3698],\n",
      "        [0.5411],\n",
      "        [0.3996],\n",
      "        [0.3549],\n",
      "        [0.6681],\n",
      "        [0.6194],\n",
      "        [0.4425],\n",
      "        [0.4136],\n",
      "        [0.5449],\n",
      "        [0.4673],\n",
      "        [0.5015],\n",
      "        [0.6595],\n",
      "        [0.5487],\n",
      "        [0.5027],\n",
      "        [0.5895],\n",
      "        [0.4270],\n",
      "        [0.5920],\n",
      "        [0.5546],\n",
      "        [0.3742],\n",
      "        [0.4014],\n",
      "        [0.4132],\n",
      "        [0.4183],\n",
      "        [0.4444],\n",
      "        [0.3366],\n",
      "        [0.4085],\n",
      "        [0.6129],\n",
      "        [0.6620],\n",
      "        [0.3698],\n",
      "        [0.4338],\n",
      "        [0.4044],\n",
      "        [0.4020],\n",
      "        [0.3765],\n",
      "        [0.3506],\n",
      "        [0.7407],\n",
      "        [0.4597],\n",
      "        [0.5467],\n",
      "        [0.5376],\n",
      "        [0.5044],\n",
      "        [0.4526],\n",
      "        [0.5027],\n",
      "        [0.3357],\n",
      "        [0.5554],\n",
      "        [0.6106],\n",
      "        [0.5975],\n",
      "        [0.5562],\n",
      "        [0.6927],\n",
      "        [0.5893],\n",
      "        [0.5771],\n",
      "        [0.4275],\n",
      "        [0.4786],\n",
      "        [0.6783],\n",
      "        [0.4542],\n",
      "        [0.6129],\n",
      "        [0.5799],\n",
      "        [0.6336],\n",
      "        [0.4381],\n",
      "        [0.5802],\n",
      "        [0.5589],\n",
      "        [0.5000],\n",
      "        [0.7112],\n",
      "        [0.3196],\n",
      "        [0.5612],\n",
      "        [0.6360],\n",
      "        [0.5215],\n",
      "        [0.6703],\n",
      "        [0.5140],\n",
      "        [0.4939],\n",
      "        [0.3720],\n",
      "        [0.3787],\n",
      "        [0.6187],\n",
      "        [0.5623],\n",
      "        [0.3676],\n",
      "        [0.5161],\n",
      "        [0.6069],\n",
      "        [0.5710],\n",
      "        [0.6366],\n",
      "        [0.3925],\n",
      "        [0.7042],\n",
      "        [0.3040],\n",
      "        [0.3658],\n",
      "        [0.5073],\n",
      "        [0.7667],\n",
      "        [0.5890],\n",
      "        [0.3445],\n",
      "        [0.4461],\n",
      "        [0.3961],\n",
      "        [0.3833],\n",
      "        [0.5062],\n",
      "        [0.6823],\n",
      "        [0.3486],\n",
      "        [0.4008],\n",
      "        [0.4082],\n",
      "        [0.3425],\n",
      "        [0.4922],\n",
      "        [0.5030]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6222076-777f-44fb-97c8-1be2a7d5fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d99a2f2-1177-4225-a41d-e2be26e94a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4771, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor(4.7050, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = MSELoss()\n",
    "loss1 = criterion(preds_train, y_train_tensor)\n",
    "loss2 = criterion(preds_test, y_test_tensor)\n",
    "print(loss1)\n",
    "print()\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f19f9d5e-39df-4e4c-9ec7-af0e0b003f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2165, -0.6344],\n",
       "        [-0.2220, -0.2484]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1509db29-b3fe-4526-a6f6-699153806867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.5388, 0.2492]], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ed780-1231-42e9-8aa9-5dc5708e597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539182c-4553-40e4-a003-8926000a66b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d424ea-6b81-4b67-ae21-0c0fd80e3326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
